### 大题考点分布

- **【简答】**计算机系统结构概念、模拟与仿真、替换算法、Flynn分类法、Cache不一致（单核下的cache主存、多核下的cache）、超标量/超流水（效率、加速比） 
- **【应用】**非线性流水线调度、互联函数、立方体多级互联网络
- **【编程】**OpenMP
- **【综合】**多级存储结构（寄存器-Cache-Memory-Storage四级缓存、为何可以优化？局部性原理）、流水处理的技术途径、SIMD技术（CPU、GPU，举例介绍）



### 第一章 计算机系统结构概论

1. 计算机系统：计算机系统是由紧密相关的软件和硬件（两部分）组成。
2. 计算机系统功能模型（洋葱图）：M0-M2级属于计算机组成与系统结构的范围，M3-M5属于系统软件的范围，M6属于应用程序的范围，M7属于系统总体分析的范围。
3. 冯·诺依曼体系结构：由运算器、控制器、存储器、和输入/输出设备组成。特点：存储器按线性地址编址访问的一维结构；指令由操作码和地址码组成；指令在存储器中按顺序存储；指令与数据不分开储存；以运算器、控制器为核心；指令、数据以二进制表示
4. **计算机系统结构**：Amdahl指出：计算机系统结构是程序设计者所看到的计算机属性，即**概念性结构和功能特性**，这实际上是计算机系统的**外特性**。计算机系统结构是指对**机器语言计算机的软、硬件功能分配和界面的定义**。
5. 透明性：在计算机技术中，本来存在的**事物或属性**，但从某种角度看又好像不存在，无法对其进行**监测或设置**。
6. **计算机系统结构，组成和实现三者的关系：**
   - 计算机系统结构、组成和实现是三个不同的概念。计算机系统结构是计算机系统的概念性结构和功能特性，计算机组成是计算机系统结构的**逻辑实现**，计算机实现是计算机组成的**物理实现**。它们各自有不同的内容，但又有紧密的联系。

   - 总而言之，系统结构、组成和实现之间的关系应符合下列原则：系统结构不要对组成、实现**有过多和不合理限制**；组成设计应在系统结构指导下，**以目前能实现的技术为基础**；实现应在组成的逻辑结构指导下，**以目前器件技术为基础，以优化性能价格比为目标**。
7. 系列机：具有相同的**系统结构**，但是组成和实现技术不同的**一系列计算机系统**。向后兼容必须做到，向上兼容尽量做到。向前兼容和向下兼容，可以不考虑。
8. **模拟与仿真**：在某个系统结构之上实现另一种**系统结构**。即在一台现有的计算机上实现另一台计算机的指令系统。**全部用软件实现的叫模拟，用软件、硬件和固件混合实现的叫仿真**。
   - 模拟与仿真的主要区别在于解释用的语言。模拟是用机器语言程序解释，其解释程序存在主存中，而仿真是用微程序解释，其解释程序存在微程序存储器中。
   - 模拟灵活，可实现不同系统间的软件移植，但结构差异太大时，效率、速度会急剧下降。
   - 仿真在速度上损失小，但不灵活，只能在差别不大的系统之间使用，否则效率也会过低且难以仿真，需与模拟结合才行。
   - <img src="C:\Users\YanXinyu\AppData\Roaming\Typora\typora-user-images\image-20230531110552157.png" alt="image-20230531110552157" style="zoom: 25%;" />
9. 软、硬件取舍和软、硬件平衡：：一般来说，提高硬件功能比例可以提高运算速度，减小存储容量，但硬件成本会上升，硬件利用率和系统的灵活性与适应性会降低；而提高软件功能比例可以降低硬件成本，提高系统的灵活性与适应性，但运算速度会下降，存储容量和软件研发费用会增加。
10. Amdahl定律
11. **计算机系统结构分类——Flynn分类法**（基于**指令流和数据流的多倍性**的计算机系统结构分类方法）
       - SISD（单指令流单数据流）：大多数串行计算机
       - SIMD（单指令流多数据流）：并行处理机、阵列处理机、【向量处理机、相联处理机、超标量处理机、超流水线处理机】。
         - MMX：64位
         - SSE：128位
         - AVX：256位
         - AVX-512：512位
         - SVE：可变长，128-2048位
       - MISD（多指令流单数据流）：无
       - MIMD（多指令流多数据流）：多处理机系统和多计算机系统
12. **SIMD与SIMT：**SIMD是一种并行计算模型，其中同一条指令同时应用于多个数据元素，这意味着在执行一条指令时，多个数据元素可以同时进行相同的操作。SIMT是一种类似于 SIMD 的并行计算模型，通过将大量线程分配到多个处理单元上并行执行，使得 SIMT 能够有效地处理具有不同输入数据的并行任务，从而实现高吞吐量的并行计算。因此SIMD 更适合于数据相同、但需要同时进行相同操作的情况，而 SIMT 更适合于同时处理多个线程，每个线程处理不同数据的情况。
13. **SIMT（CUDA）和SIMD的区别**：**SIMT将一条指令并行应用于多个独立的进程，而非多个数据通道。SIMD一个控制单元很多处理单元，提高速度只能增加硬件**（也可以说CUDA基础是SIMD，因为SIMT源于SIMD）。
14. **SIMT应该如何增加并行度，提高速度：**

    + **并行任务设计**：将任务划分为更多的独立子任务，并确保这些子任务之间没有依赖关系。这样可以增加并行度，使得更多的线程可以同时执行独立的任务，从而提高整体速度。
    + **线程块的数量和大小**：线程块是 SIMT 模型中的基本执行单元。增加线程块的数量可以同时执行更多的任务，而增加线程块的大小可以利用更多的线程来处理更多的数据。
    + **内存访问优化**：在 SIMT 模型中，线程需要从内存中读取数据进行计算。优化内存访问可以减少内存延迟，提高整体的执行效率。例如使用合适的内存布局、利用共享内存来减少全局内存的访问等技术都可以提高内存访问效率。
    + **数据分块和负载均衡**：将数据分块处理，并合理分配给不同的线程块，可以实现负载均衡，确保每个线程块的工作量均衡，充分利用硬件资源，提高并行度和速度。
    + **算法和计算模式的优化**：针对具体的计算任务，优化算法和计算模式可以减少不必要的计算量和数据传输，提高计算效率。包括减少冗余计算、利用并行算法和数据结构、避免线程间同步等。
    + **硬件架构和设备选择**：不同的GPU设备具有不同的架构和性能特点。选择合适的硬件架构和设备可以最大限度地发挥 SIMT 模型的并行能力，提高速度。
    **具体的优化方法和策略可能因应用场景、硬件设备和算法需求而有所不同，需要根据实际情况进行调试和优化。**



### 第2章 处理器及其相关技术 

1. **OpenMP**
![image-20230531133535530](C:\Users\YanXinyu\AppData\Roaming\Typora\typora-user-images\image-20230531133535530.png)
- OpenMP的编程模型以**线程**为基础，通过**编译制导指令【语句】（形如#pragma omp ...）**来显示地制导并行化
- OpenMP的执行模式采用了**Fork-Join**的形式。Fork-Join执行模式在开始执行的时候，只有一个**“主线程”**在运行。主线程在运行过程中，当遇到需要进行并行计算的时候，会派生出线程来进行并行执行。在并行执行开始时（即Fork阶段），主线程和派生线程被分配到空闲的CPU内核上并行执行；当线程执行完成后，就会退出并释放CPU内核（即Join阶段），当所有线程都完成后，主线程将开始继续执行串行部分，这就是一个Fork-Join过程。**一个OpenMP程序可以有若干这样的过程，每个过程还可以嵌套Fork-Join过程。**

2. GPU/CUDA
   - GPU中的**【基本运算单元】**：**流处理器**SP
   - GPU**执行指令**的**基本单位**：**流多处理器**SM
   - CUDA定义了“**主机-设备**”的GPU编程**模式**，基于**SIMD编程模型**，在GPU上执行的代码被称为**核函数**
   - CUDA线程分为：**线程、线程块、网格。线程是【CUDA程序】的基本执行单元。**



### 第3章 存储系统结构 

1. **堆栈型算法**：堆栈型替换算法不是指某一种算法，更不是指堆栈本身，而是指一类算法。堆栈型算法研究**分配给程序的主存页面数的增加与命中率的关系**

   对任意一个程序的页地址流作两次主存页面数分配，分别分配m个主存页面和n个主存页面，且m＜n。如果在任何时刻t，k时刻的页面集Bt(k)都满足关系Bt(m)⊂Bt(n)，则这类算法称为堆栈型算法。

   基本特点是随着分配给程序的主存页面数增加，主存的命中率也提高，至少不下降。如LRU、OPT、LFU等。

   而FIFO不是堆栈型算法，其存在Belady现象。即如果对一个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多，但缺页率反而提高的异常现象。

   FIFO: 每次替换最先进入的页面。

   LRU: 每次替换之前最久没有使用的页面

   OPT: 每次替换之后最少使用的页面

   FIFO 不是堆栈型。LRU,OPT 为堆栈型。

   

2. **Cache一致性问题**：Cache内存储的信息是贮存内存储的**部分信息的副本**，在一段时间内，两者对应单元的内容可能是不同的，因为存在：

   + **CPU写Cache，但没有立即写主存。**
   + **IO处理机或IO设备写主存，但没有写Cache。**

   为了解决Cache一致性问题，人们提出了**主存修改算法**，一般可用两种：

   写回法:仅在cache替换时才将修改的cache块写回主存(需要标志位)，当cache写不命中时除写入主存外，还把该单元所在块由主存调入cache。
   写直达法:在修改cache的同时直接写入主存，当cache写不命中时只写入主存，该单元所在块不从主存调入cache。
   
   算法特点：
   
   + 可靠性、控制的复杂性：写直达法优于写回法
   
   + 与主存的通信量、硬件实现的代价：写回法少于写直达法



3. **存储系统速度提高的方式**：1.提高命中率，2.两个存储器的速度不要相差太大。Cache存储系统速度接近Cache的速度，存储容量是主存的容量，单位价格接近主存储器的单位价格。虚拟存储系统的速度接近主存储器的速度，存储容量是虚拟地址空间，单位价格接近磁盘存储器的单位价格。

   存储系统的提高主要依赖于提高命中率，提高命中率依赖于预取（局部性原理），预取算法有按需取、恒预取、不命中预取。

   存储系统还可以依靠并行提高效率：高位交叉、低位交叉。只有低位交叉才能够有效解决访问冲突问题，真正的提高效率。它是一种采用流水线方式工作的并行存储系统。在连续工作的情况下，保持每个存储体速度不变，则由n个存储体组成的存储器速度可望提高n倍。但加速比通常小于n，原因在于访问冲突：取指令时可能发生程序转移，取操作数时存在数据离散性。



​		通过使用低位交叉存储器，数据位可以被分散存储在多个存储芯片中，并实现并行访问。 



### 第4章 流水线结构

1. 流水线在T时间内，每段的时间是$\bigtriangleup  t_i$

   最大吞吐率是$\mathbf{TP_{max}=\frac{1}{\max\{\bigtriangleup  t_i\}}}$,

   加速比$\textbf{S}=\frac{T_{非流水}}{T_{流水}}=\frac{mn \bigtriangleup  t_0}{m\bigtriangleup  t_0+(n-1)\bigtriangleup  t_0}=\frac{mn}{m+n-1}$, 

   效率$\textbf{E}=\frac{e_1+e_2 +\dots +e_m}{m}=\frac{me_0}{m}=\frac{mn\bigtriangleup  t_0}{mT}$

2. 单流水线标量处理机的ILP记作(1,1)，超标量的记作(m,1)，超流水线记作(1,n)。K是流水线级数，$\bigtriangleup  t$是时钟周期，$T(1,1)=(K+N-1) × \bigtriangleup  t$

   - N条指令在一个$\bigtriangleup  t$内发射m条指令的超标量处理机上执行所需要的时间为：$T(m,1)=(K+\left \lceil \frac{N-m}{m} \right \rceil ) × \bigtriangleup  t$，加速比为$S(m,1)=\frac{T(1,1)}{T(m,1)}=\frac{m(K+N-1)}{N+m(K-1)}$，

   - N条指令在一个$\bigtriangleup  t$内发射n条指令的超流水线处理机所需时间为$T(1,n)=(K+\frac{N-1}{n}) × \bigtriangleup  t$，加速比为$S(1,n)=\frac{T(1,1)}{T(1,n)}=\frac{n(K+N-1)}{nK+N-1}$

   - 是和单标量作比较的，不是和串行程序比较。	

3. 数据相关，对F~1~来说：

   + 写写相关：写后再写如$F_1 \leftarrow (A)，F_1 \leftarrow (F_2) × (F_3)$
   + 写读相关：写后再读如$F_1 \leftarrow (A)，F_3 \leftarrow (F_1) × (F_2)$
   + 读写相关：读后再写如$F_3 \leftarrow (F_1) × (F_2)，F_1 \leftarrow (A)$

4. **超标量与超流水处理机的区别：**

   超流水线处理机的工作方式与超标量处理机不同，超标量是以增加硬件资源为代价来换取处理机性能，而超流水线处理机是通过部分硬件的充分重叠工作提高处理机性能的。超标量是空间并行性，超流水线是时间并行性。



+ **SIMD和SIMT**

  SIMD系统结构以并行处理机（阵列处理机）为代表，其在同一个控制部件的管理下，有多个处理部件接受从控制部件送来的同一条指令。工作方式是阵列内各个处理单元对各自分配的不同数据并行执行同一条规定操作，存储器结构是分布式存储器结构和共享式存储器结构。SIMD适用于大量高速向量或矩阵运算的场景。实现了SIMD的主要技术有Intel的MMX、SSE、AVX等。

  SIMT也是一种类似于 SIMD 的并行计算模型，由NVIDIA针对SIMD再GPU上的应用和发展变化提出的。SIMT通过将大量线程分配到多个处理单元上并行执行，使得 SIMT 能够有效地处理具有不同输入数据的并行任务，从而实现高吞吐量的并行计算。

  **SIMT（CUDA）和SIMD的区别**： SIMD 将一条指令应用于多个数据通道。 SIMT 架构类似 SIMD 设计，不同之处在于 SIMT 将一条指令并行应用于多个独立线程，而不仅仅是多个数据通道。

  SIMD 无法执行分支和不同种指令，SIMT 指令可以控制一个线程的执行和分支行为。SIMT 在执行分支指令时使用“屏蔽”的方法。

  **SIMT应该如何增加并行度，提高速度：**

  + **并行任务设计**：将任务划分为更多的独立子任务，并确保这些子任务之间没有依赖关系。这样可以增加并行度，使得更多的线程可以同时执行独立的任务，从而提高整体速度。
  + **线程块的数量和大小**：线程块是 SIMT 模型中的基本执行单元。增加线程块的数量可以同时执行更多的任务，而增加线程块的大小可以利用更多的线程来处理更多的数据。
  + **内存访问优化**：在 SIMT 模型中，线程需要从内存中读取数据进行计算。优化内存访问可以减少内存延迟，提高整体的执行效率。例如使用合适的内存布局、利用共享内存来减少全局内存的访问等技术都可以提高内存访问效率。
  + **数据分块和负载均衡**：将数据分块处理，并合理分配给不同的线程块，可以实现负载均衡，确保每个线程块的工作量均衡，充分利用硬件资源，提高并行度和速度。
  + **算法和计算模式的优化**：针对具体的计算任务，优化算法和计算模式可以减少不必要的计算量和数据传输，提高计算效率。包括减少冗余计算、利用并行算法和数据结构、避免线程间同步等。
  + **硬件架构和设备选择**：不同的GPU设备具有不同的架构和性能特点。选择合适的硬件架构和设备可以最大限度地发挥 SIMT 模型的并行能力，提高速度。
    **具体的优化方法和策略可能因应用场景、硬件设备和算法需求而有所不同，需要根据实际情况进行调试和优化。**

  

  

  **存储系统速度提高的方式**

  存储系统分为：寄存器-Cache-主存-外存四级。

  提高速度的思路主要分为：1.提高命中率，2.两个存储器的速度不要相差太大。其中，第二条有时做不到，这时只能依靠**提高命中率**。提高命中率的方法依赖于预取，预取依赖于局部性原理。

  目前速度快的存储器价格贵，容量小;价格低的存储器速度慢，容量大。在计算机存储器体系结构设计时，我们希望存储器系统的性能高、价格低，为了解决速度、容 量、成本这三者的矛盾，依据 程序局部性原理，在存储器容量，速度和价格方面的因素作折中考 虑，建立了分层次的存储器体系结构:

  

   高速缓冲存储器(cache/缓存) 在计算机存储系统的层次结构中，是介于中央处理器和主存储器 之间的高速小容量存储器。存在于主存与CPU之间的一级存储器，由静态存储芯片(SRAM)组成， 容量比较小但速度比主存高得多，接近于CPU的速度。

  高速缓冲存储器本身**以前只有单一的Cache，现在有L1L2在CPU内部，L3有的做在板上，并不一定在CPU内部。

  主存储器(主存) 是计算机系统的主要存储器，用来存放计算机运行期间的大量程序和数据。 

  外存储器(外存) 它是大容量辅助存储器。

  将常用的数据保存在高速缓存中，可以大大提高访问速度。对于不常用但仍然需要保存的数据， 可以使用主存储器。而那些不常用的数据则可以保存在辅助存储器中。

  

  Cache-主存层次：弥补主存速度不足，解决CPU和主存速度不匹配

  使用多体叉存储器（主存并行）提高效率：高位交叉、低位交叉。只有低位交叉才能够有效解决访问冲突问题，真正的提高效率。它是一种采用流水线方式工作的并行存储系统。通过使用低位交叉存储器，数据位可以被分散存储在多个存储芯片中，并实现并行访问。 

  主存-辅存层次：弥补容量差距

  增加物理内存 虚拟内存 运行时折中 快表

  

  

  流水线技术：

  

  推广到操作部件级、处理机级，有一系些概念：P123关于流水线原理的介绍，流水处理法技术途径4.1.3节第一部分说明。流水线技术的特点：划分为若干个子过程、实现实现了复用段尽可能时间相等，通过时间、可能出现中断，适用于大量的重复的过程，这些特点其实也就是我们去实现流水线所采用的的方式。（把这一部分通读，总结按你的方式表述）

  

  

  

  ```
  # -o是指定生成文件的文件名 g++ -o omp omp.cpp -fopenmp # 编译命令 ./omp # 执行命令
  ```

  

  初始化

  reduction需要针对线程逐个计算会影响性能

  schedule static dynamic

  负载均衡里有一个如下。static编译的时候就计算工作量然后分配线程，dynamic运行的时候调度，给执行快的线程申请更多任务。
